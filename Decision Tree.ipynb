{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1b8b00",
   "metadata": {},
   "source": [
    "# üìò Decision Trees Concepts and Python Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2abf5a",
   "metadata": {},
   "source": [
    "\n",
    "## üå≤ Decision Trees - Key Concepts\n",
    "\n",
    "### What is a Decision Tree, and how does it work?\n",
    "A Decision Tree is a flowchart-like structure where each internal node represents a decision based on a feature, each branch represents an outcome, and each leaf node represents a class label or value. It splits data into subsets based on feature values using criteria like Gini impurity or entropy.\n",
    "\n",
    "### Impurity Measures in Decision Trees\n",
    "- **Gini Impurity** and **Entropy** are used to measure the impurity or disorder of a dataset.\n",
    "\n",
    "### Gini Impurity Formula\n",
    "\\[\n",
    "Gini = 1 - \\sum_{i=1}^{n} p_i^2\n",
    "\\]\n",
    "\n",
    "### Entropy Formula\n",
    "\\[\n",
    "Entropy = - \\sum_{i=1}^{n} p_i \\log_2(p_i)\n",
    "\\]\n",
    "\n",
    "### Information Gain\n",
    "- The reduction in impurity from a split:\n",
    "\\[\n",
    "Information Gain = Entropy_{parent} - \\sum \\frac{|child|}{|parent|} Entropy_{child}\n",
    "\\]\n",
    "\n",
    "### Gini vs Entropy\n",
    "- Both measure impurity; Gini is faster to compute, Entropy gives more weight to rare classes.\n",
    "\n",
    "### Pre-Pruning\n",
    "Stop growing tree early by limiting depth, minimum samples, etc.\n",
    "\n",
    "### Post-Pruning\n",
    "Grow full tree first, then remove branches that add little predictive value (Cost Complexity Pruning).\n",
    "\n",
    "### Pre-Pruning vs Post-Pruning\n",
    "- **Pre-Pruning**: Stops early.\n",
    "- **Post-Pruning**: Removes later.\n",
    "\n",
    "### Decision Tree Regressor\n",
    "Predicts continuous values by splitting data to minimize variance.\n",
    "\n",
    "### Advantages and Disadvantages\n",
    "‚úÖ Easy to interpret, no need for scaling, works for categorical data.  \n",
    "‚ùå Prone to overfitting, unstable with small changes.\n",
    "\n",
    "### Missing Values\n",
    "Can split on available features or use surrogate splits.\n",
    "\n",
    "### Categorical Features\n",
    "Handled by splitting on each category or using dummy encoding.\n",
    "\n",
    "### Real-World Applications\n",
    "Fraud detection, customer segmentation, medical diagnosis, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca76cae8",
   "metadata": {},
   "source": [
    "### ‚úÖ Train Decision Tree Classifier on Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca9e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0369cc3e",
   "metadata": {},
   "source": [
    "### ‚úÖ Gini Criterion & Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_gini = DecisionTreeClassifier(criterion='gini')\n",
    "clf_gini.fit(X_train, y_train)\n",
    "print(\"Feature importances:\", clf_gini.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0035b73",
   "metadata": {},
   "source": [
    "### ‚úÖ Entropy Criterion & Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c114975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_entropy = DecisionTreeClassifier(criterion='entropy')\n",
    "clf_entropy.fit(X_train, y_train)\n",
    "print(\"Accuracy (Entropy):\", accuracy_score(y_test, clf_entropy.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f6203b",
   "metadata": {},
   "source": [
    "### ‚úÖ Decision Tree Regressor on Boston Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98f4fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "boston = load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.3, random_state=42)\n",
    "reg = DecisionTreeRegressor()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cbe28d",
   "metadata": {},
   "source": [
    "### ‚úÖ Visualize Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd478a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, feature_names=iris.feature_names, class_names=iris.target_names, filled=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"decision_tree_iris\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc782c97",
   "metadata": {},
   "source": [
    "### ‚úÖ max_depth=3 vs Full Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2ee6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_full = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "clf_limited = DecisionTreeClassifier(max_depth=3).fit(X_train, y_train)\n",
    "print(\"Full tree accuracy:\", accuracy_score(y_test, clf_full.predict(X_test)))\n",
    "print(\"Max depth=3 accuracy:\", accuracy_score(y_test, clf_limited.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d2c0be",
   "metadata": {},
   "source": [
    "### ‚úÖ min_samples_split=5 vs Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea035921",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_default = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "clf_min_samples = DecisionTreeClassifier(min_samples_split=5).fit(X_train, y_train)\n",
    "print(\"Default accuracy:\", accuracy_score(y_test, clf_default.predict(X_test)))\n",
    "print(\"min_samples_split=5 accuracy:\", accuracy_score(y_test, clf_min_samples.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262dd987",
   "metadata": {},
   "source": [
    "### ‚úÖ Feature Scaling Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1275b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf_scaled = DecisionTreeClassifier().fit(X_train_scaled, y_train)\n",
    "print(\"Scaled data accuracy:\", accuracy_score(y_test, clf_scaled.predict(X_test)))\n",
    "print(\"Unscaled data accuracy:\", accuracy_score(y_test, clf_default.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a11241b",
   "metadata": {},
   "source": [
    "### ‚úÖ One-vs-Rest Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7e4c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "ovr_clf = OneVsRestClassifier(DecisionTreeClassifier())\n",
    "ovr_clf.fit(X_train, y_train)\n",
    "print(\"OvR Accuracy:\", accuracy_score(y_test, ovr_clf.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f1e400",
   "metadata": {},
   "source": [
    "### ‚úÖ Decision Tree Regressor with max_depth=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d9dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reg_full = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "reg_limited = DecisionTreeRegressor(max_depth=5).fit(X_train, y_train)\n",
    "print(\"Full tree MSE:\", mean_squared_error(y_test, reg_full.predict(X_test)))\n",
    "print(\"Max depth=5 MSE:\", mean_squared_error(y_test, reg_limited.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0535f57",
   "metadata": {},
   "source": [
    "### ‚úÖ Cost Complexity Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b69a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf_pruned = DecisionTreeClassifier(ccp_alpha=ccp_alpha).fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_test, clf_pruned.predict(X_test))\n",
    "    print(f\"ccp_alpha={ccp_alpha:.5f}, accuracy={acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
